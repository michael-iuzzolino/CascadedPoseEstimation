{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pose_estimation._init_paths\n",
    "\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment',None)\n",
    "import glob\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from core.evaluate import accuracy\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import dataset\n",
    "from core.config import config\n",
    "# from core.config import update_config\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "import utils.flops_benchmarker\n",
    "import argparse\n",
    "import models.pose_stacked_hg\n",
    "from utils.utils import create_experiment_directory\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _update_dict(k, v):\n",
    "    if k == \"DATASET\":\n",
    "        if \"MEAN\" in v and v[\"MEAN\"]:\n",
    "            v[\"MEAN\"] = np.array([eval(x) if isinstance(x, str) else x\n",
    "                                  for x in v[\"MEAN\"]])\n",
    "        if \"STD\" in v and v[\"STD\"]:\n",
    "            v[\"STD\"] = np.array([eval(x) if isinstance(x, str) else x\n",
    "                                 for x in v[\"STD\"]])\n",
    "    if k == \"MODEL\":\n",
    "        if \"EXTRA\" in v and \"HEATMAP_SIZE\" in v[\"EXTRA\"]:\n",
    "            if isinstance(v[\"EXTRA\"][\"HEATMAP_SIZE\"], int):\n",
    "                v[\"EXTRA\"][\"HEATMAP_SIZE\"] = np.array(\n",
    "                    [v[\"EXTRA\"][\"HEATMAP_SIZE\"], v[\"EXTRA\"][\"HEATMAP_SIZE\"]])\n",
    "            else:\n",
    "                v[\"EXTRA\"][\"HEATMAP_SIZE\"] = np.array(\n",
    "                    v[\"EXTRA\"][\"HEATMAP_SIZE\"])\n",
    "        if \"IMAGE_SIZE\" in v:\n",
    "            if isinstance(v[\"IMAGE_SIZE\"], int):\n",
    "                v[\"IMAGE_SIZE\"] = np.array([v[\"IMAGE_SIZE\"], v[\"IMAGE_SIZE\"]])\n",
    "            else:\n",
    "                v[\"IMAGE_SIZE\"] = np.array(v[\"IMAGE_SIZE\"])\n",
    "    for vk, vv in v.items():\n",
    "        if vk in config[k]:\n",
    "            config[k][vk] = vv\n",
    "        else:\n",
    "            raise ValueError(f\"{k}.{vk} not exist in config.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config(config, config_file):\n",
    "    exp_config = None\n",
    "    with open(config_file) as f:\n",
    "        exp_config = edict(yaml.load(f))\n",
    "        for k, v in exp_config.items():\n",
    "            if k in config:\n",
    "                if isinstance(v, dict):\n",
    "                    _update_dict(k, v)\n",
    "                else:\n",
    "                    if k == \"SCALES\":\n",
    "                        config[k][0] = (tuple(v))\n",
    "                    else:\n",
    "                        config[k] = v\n",
    "            else:\n",
    "                raise ValueError(f\"{k} not exist in config.py\")\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(cfg_path=\"\"):\n",
    "    parser = argparse.ArgumentParser(description='Train keypoints network')\n",
    "#     # general\n",
    "#     parser.add_argument('--cfg',\n",
    "#                         help='experiment configure file name',\n",
    "#                         required=True,\n",
    "#                         type=str)\n",
    "    if cfg_path:\n",
    "      default_cfg = cfg_path\n",
    "    else:\n",
    "      default_cfg = \"experiments/mpii/hourglass_8__teacher.yaml\"\n",
    "    parser.add_argument('--cfg',\n",
    "                        help='experiment configure file name',\n",
    "                        default=default_cfg,\n",
    "                        type=str)\n",
    "\n",
    "    args, rest = parser.parse_known_args()\n",
    "    # update config\n",
    "#     update_config(args.cfg)\n",
    "\n",
    "    # training\n",
    "    parser.add_argument('--frequent',\n",
    "                        help='frequency of logging',\n",
    "                        default=config.PRINT_FREQ,\n",
    "                        type=int)\n",
    "    parser.add_argument('--max_batch_logs',\n",
    "                        help='Max # of batches to save data from',\n",
    "                        default=5,\n",
    "                        type=int)\n",
    "    parser.add_argument('--gpus',\n",
    "                        help='gpus',\n",
    "                        type=str)\n",
    "    parser.add_argument('--workers',\n",
    "                        help='num of dataloader workers',\n",
    "                        type=int)\n",
    "    parser.add_argument('--model-file',\n",
    "                        help='model state file',\n",
    "                        type=str)\n",
    "    parser.add_argument('--result_root',\n",
    "                        default=\"/hdd/mliuzzolino/TDPoseEstimation/results/\",\n",
    "                        help='Root for results',\n",
    "                        type=str)\n",
    "    parser.add_argument('--threshold',\n",
    "                        type=float,\n",
    "                        default=0.5,\n",
    "                        help='Accuracy threshold [default=0.5]')\n",
    "    parser.add_argument('--use-detect-bbox',\n",
    "                        help='use detect bbox',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--flip-test',\n",
    "                        help='use flip test',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--load_best_ckpt',\n",
    "                        help='Load best checkpoint [default: load final]',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--post-process',\n",
    "                        help='use post process',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--shift-heatmap',\n",
    "                        help='shift heatmap',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--force_overwrite',\n",
    "                        help='Force overwrite',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--vis_output_only',\n",
    "                        help='Visualize output only; dont save results',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--save_all_data',\n",
    "                        help='Save all data',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--coco-bbox-file',\n",
    "                        help='coco detection bbox file',\n",
    "                        type=str)\n",
    "\n",
    "    args = parser.parse_args(\"\")\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_config(config, args):\n",
    "    if args.gpus:\n",
    "        config.GPUS = args.gpus\n",
    "    if args.workers:\n",
    "        config.WORKERS = args.workers\n",
    "    if args.use_detect_bbox:\n",
    "        config.TEST.USE_GT_BBOX = not args.use_detect_bbox\n",
    "    if args.flip_test:\n",
    "        config.TEST.FLIP_TEST = args.flip_test\n",
    "    if args.post_process:\n",
    "        config.TEST.POST_PROCESS = args.post_process\n",
    "    if args.shift_heatmap:\n",
    "        config.TEST.SHIFT_HEATMAP = args.shift_heatmap\n",
    "    if args.model_file:\n",
    "        config.TEST.MODEL_FILE = args.model_file\n",
    "    if args.coco_bbox_file:\n",
    "        config.TEST.COCO_BBOX_FILE = args.coco_bbox_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-e95f61268cc2>:4: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  exp_config = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "reset_config(config, args)\n",
    "config = update_config(config, args.cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dataset' has no attribute 'coco'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-af942a03c699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.229\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.225\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0;31m valid_dataset = eval('dataset.coco')(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dataset' has no attribute 'coco'"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(\n",
    "  mean=[0.485, 0.456, 0.406],\n",
    "  std=[0.229, 0.224, 0.225],\n",
    ")\n",
    "valid_dataset = eval('dataset.coco')(\n",
    "    config,\n",
    "    config.DATASET.ROOT,\n",
    "    config.DATASET.TEST_SET,\n",
    "    False,\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x_data, target, target_weight, meta) in enumerate(valid_loader):\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = f\"experiments/mpii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hourglass_8__td_0__no_shared__distill.yaml\n",
      "hourglass_8__td_0__no_shared__no_distill.yaml\n",
      "hourglass_8__td_0__shared__distill.yaml\n",
      "hourglass_8__td_0__shared__no_distill.yaml\n",
      "hourglass_8__teacher.yaml\n"
     ]
    }
   ],
   "source": [
    "[print(ele) for ele in np.sort(os.listdir(root)) if ele.endswith(\".yaml\")];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = os.path.join(root, \"hourglass_8__teacher.yaml\")\n",
    "cfg_path = os.path.join(root, \"hourglass_8__td_0__shared__no_distill.yaml\")\n",
    "# cfg_path = os.path.join(root, \"hourglass_8__td_0__shared__distill.yaml\")\n",
    "# cfg_path = os.path.join(root, \"hourglass_8__td_0__no_shared__no_distill.yaml\")\n",
    "# cfg_path = os.path.join(root, \"hourglass_8__td_0__no_shared__distill.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-e95f61268cc2>:4: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  exp_config = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "args = parse_args(cfg_path)\n",
    "reset_config(config, args)\n",
    "config = update_config(config, args.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/mpii/hourglass_x8__TD_0.0__shared\n"
     ]
    }
   ],
   "source": [
    "output_dir = create_experiment_directory(\n",
    "    config,\n",
    "    args.cfg,\n",
    "    distillation=False,\n",
    "    make_dir=False,\n",
    ")\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.pose_stacked_hg.get_pose_net(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_params: 660,496\n"
     ]
    }
   ],
   "source": [
    "n_params = 0\n",
    "for key, param in model.named_parameters():\n",
    "  if param.requires_grad:\n",
    "    n_params += param.numel() \n",
    "print(f\"n_params: {n_params:,}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x_data, log_flops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.567884288,\n",
       " 0.567884288,\n",
       " 0.567884288,\n",
       " 0.567884288,\n",
       " 0.567884288,\n",
       " 0.567884288,\n",
       " 0.567884288,\n",
       " 0.567884288]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.total_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.56788429, 1.13576858, 1.70365286, 2.27153715, 2.83942144,\n",
       "       3.40730573, 3.97519002, 4.5430743 ])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(model.total_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.567884288,\n",
       " 1.135768576,\n",
       " 1.703652864,\n",
       " 2.271537152,\n",
       " 2.83942144,\n",
       " 3.407305728,\n",
       " 3.975190016,\n",
       " 4.543074304]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.total_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.total_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.flops_benchmarker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
