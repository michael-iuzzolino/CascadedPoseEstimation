{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find coco.\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pose_estimation._init_paths\n",
    "\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "pd.set_option('mode.chained_assignment',None)\n",
    "import glob\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "from core.evaluate import accuracy\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import dataset\n",
    "from core.config import config\n",
    "# from core.config import update_config\n",
    "import yaml\n",
    "from easydict import EasyDict as edict\n",
    "import utils.flops_benchmarker\n",
    "import argparse\n",
    "import models.pose_stacked_hg\n",
    "from utils.utils import create_experiment_directory\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _update_dict(k, v):\n",
    "    if k == \"DATASET\":\n",
    "        if \"MEAN\" in v and v[\"MEAN\"]:\n",
    "            v[\"MEAN\"] = np.array([eval(x) if isinstance(x, str) else x\n",
    "                                  for x in v[\"MEAN\"]])\n",
    "        if \"STD\" in v and v[\"STD\"]:\n",
    "            v[\"STD\"] = np.array([eval(x) if isinstance(x, str) else x\n",
    "                                 for x in v[\"STD\"]])\n",
    "    if k == \"MODEL\":\n",
    "        if \"EXTRA\" in v and \"HEATMAP_SIZE\" in v[\"EXTRA\"]:\n",
    "            if isinstance(v[\"EXTRA\"][\"HEATMAP_SIZE\"], int):\n",
    "                v[\"EXTRA\"][\"HEATMAP_SIZE\"] = np.array(\n",
    "                    [v[\"EXTRA\"][\"HEATMAP_SIZE\"], v[\"EXTRA\"][\"HEATMAP_SIZE\"]])\n",
    "            else:\n",
    "                v[\"EXTRA\"][\"HEATMAP_SIZE\"] = np.array(\n",
    "                    v[\"EXTRA\"][\"HEATMAP_SIZE\"])\n",
    "        if \"IMAGE_SIZE\" in v:\n",
    "            if isinstance(v[\"IMAGE_SIZE\"], int):\n",
    "                v[\"IMAGE_SIZE\"] = np.array([v[\"IMAGE_SIZE\"], v[\"IMAGE_SIZE\"]])\n",
    "            else:\n",
    "                v[\"IMAGE_SIZE\"] = np.array(v[\"IMAGE_SIZE\"])\n",
    "    for vk, vv in v.items():\n",
    "        if vk in config[k]:\n",
    "            config[k][vk] = vv\n",
    "        else:\n",
    "            raise ValueError(f\"{k}.{vk} not exist in config.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_config(config, config_file):\n",
    "    exp_config = None\n",
    "    with open(config_file) as f:\n",
    "        exp_config = edict(yaml.load(f))\n",
    "        for k, v in exp_config.items():\n",
    "            if k in config:\n",
    "                if isinstance(v, dict):\n",
    "                    _update_dict(k, v)\n",
    "                else:\n",
    "                    if k == \"SCALES\":\n",
    "                        config[k][0] = (tuple(v))\n",
    "                    else:\n",
    "                        config[k] = v\n",
    "            else:\n",
    "                raise ValueError(f\"{k} not exist in config.py\")\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args(cfg_path=\"\"):\n",
    "    parser = argparse.ArgumentParser(description='Train keypoints network')\n",
    "#     # general\n",
    "#     parser.add_argument('--cfg',\n",
    "#                         help='experiment configure file name',\n",
    "#                         required=True,\n",
    "#                         type=str)\n",
    "    if cfg_path:\n",
    "      default_cfg = cfg_path\n",
    "    else:\n",
    "      default_cfg = \"experiments/mpii/hourglass_8__td_1.yaml\"\n",
    "    parser.add_argument('--cfg',\n",
    "                        help='experiment configure file name',\n",
    "                        default=default_cfg,\n",
    "                        type=str)\n",
    "\n",
    "    args, rest = parser.parse_known_args()\n",
    "    # update config\n",
    "#     update_config(args.cfg)\n",
    "\n",
    "    # training\n",
    "    parser.add_argument('--frequent',\n",
    "                        help='frequency of logging',\n",
    "                        default=config.PRINT_FREQ,\n",
    "                        type=int)\n",
    "    parser.add_argument('--max_batch_logs',\n",
    "                        help='Max # of batches to save data from',\n",
    "                        default=5,\n",
    "                        type=int)\n",
    "    parser.add_argument('--gpus',\n",
    "                        help='gpus',\n",
    "                        type=str)\n",
    "    parser.add_argument('--workers',\n",
    "                        help='num of dataloader workers',\n",
    "                        type=int)\n",
    "    parser.add_argument('--model-file',\n",
    "                        help='model state file',\n",
    "                        type=str)\n",
    "    parser.add_argument('--result_root',\n",
    "                        default=\"/hdd/mliuzzolino/TDPoseEstimation/results/\",\n",
    "                        help='Root for results',\n",
    "                        type=str)\n",
    "    parser.add_argument('--threshold',\n",
    "                        type=float,\n",
    "                        default=0.5,\n",
    "                        help='Accuracy threshold [default=0.5]')\n",
    "    parser.add_argument('--use-detect-bbox',\n",
    "                        help='use detect bbox',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--flip-test',\n",
    "                        help='use flip test',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--load_best_ckpt',\n",
    "                        help='Load best checkpoint [default: load final]',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--post-process',\n",
    "                        help='use post process',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--shift-heatmap',\n",
    "                        help='shift heatmap',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--force_overwrite',\n",
    "                        help='Force overwrite',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--vis_output_only',\n",
    "                        help='Visualize output only; dont save results',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--save_all_data',\n",
    "                        help='Save all data',\n",
    "                        action='store_true')\n",
    "    parser.add_argument('--coco-bbox-file',\n",
    "                        help='coco detection bbox file',\n",
    "                        type=str)\n",
    "\n",
    "    args = parser.parse_args(\"\")\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_config(config, args):\n",
    "    if args.gpus:\n",
    "        config.GPUS = args.gpus\n",
    "    if args.workers:\n",
    "        config.WORKERS = args.workers\n",
    "    if args.use_detect_bbox:\n",
    "        config.TEST.USE_GT_BBOX = not args.use_detect_bbox\n",
    "    if args.flip_test:\n",
    "        config.TEST.FLIP_TEST = args.flip_test\n",
    "    if args.post_process:\n",
    "        config.TEST.POST_PROCESS = args.post_process\n",
    "    if args.shift_heatmap:\n",
    "        config.TEST.SHIFT_HEATMAP = args.shift_heatmap\n",
    "    if args.model_file:\n",
    "        config.TEST.MODEL_FILE = args.model_file\n",
    "    if args.coco_bbox_file:\n",
    "        config.TEST.COCO_BBOX_FILE = args.coco_bbox_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-261-e95f61268cc2>:4: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  exp_config = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "reset_config(config, args)\n",
    "config = update_config(config, args.cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'dataset' has no attribute 'coco'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-268-af942a03c699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mstd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.229\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.225\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0;31m valid_dataset = eval('dataset.coco')(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATASET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mROOT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'dataset' has no attribute 'coco'"
     ]
    }
   ],
   "source": [
    "normalize = transforms.Normalize(\n",
    "  mean=[0.485, 0.456, 0.406],\n",
    "  std=[0.229, 0.224, 0.225],\n",
    ")\n",
    "valid_dataset = eval('dataset.coco')(\n",
    "    config,\n",
    "    config.DATASET.ROOT,\n",
    "    config.DATASET.TEST_SET,\n",
    "    False,\n",
    "    transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (x_data, target, target_weight, meta) in enumerate(valid_loader):\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = f\"experiments/mpii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hourglass_4__td_0.yaml\n",
      "hourglass_4__td_0_25.yaml\n",
      "hourglass_4__td_0_25__distill_td_0.yaml\n",
      "hourglass_4__td_0_25__distill_td_0_25.yaml\n",
      "hourglass_4__td_0_25__distill_td_0_5.yaml\n",
      "hourglass_4__td_0_25__distill_td_0_9.yaml\n",
      "hourglass_4__td_0_25__distill_td_1.yaml\n",
      "hourglass_4__td_0_25__double.yaml\n",
      "hourglass_4__td_0_5.yaml\n",
      "hourglass_4__td_0_5__distill_td_0.yaml\n",
      "hourglass_4__td_0_5__distill_td_0_25.yaml\n",
      "hourglass_4__td_0_5__distill_td_0_5.yaml\n",
      "hourglass_4__td_0_5__distill_td_0_9.yaml\n",
      "hourglass_4__td_0_5__distill_td_1.yaml\n",
      "hourglass_4__td_0_5__double.yaml\n",
      "hourglass_4__td_0_9.yaml\n",
      "hourglass_4__td_0_9__distill_td_0.yaml\n",
      "hourglass_4__td_0_9__distill_td_0_25.yaml\n",
      "hourglass_4__td_0_9__distill_td_0_5.yaml\n",
      "hourglass_4__td_0_9__distill_td_0_9.yaml\n",
      "hourglass_4__td_0_9__distill_td_1.yaml\n",
      "hourglass_4__td_0_9__double.yaml\n",
      "hourglass_4__td_0__distill_td_0.yaml\n",
      "hourglass_4__td_0__distill_td_0_25.yaml\n",
      "hourglass_4__td_0__distill_td_0_5.yaml\n",
      "hourglass_4__td_0__distill_td_0_9.yaml\n",
      "hourglass_4__td_0__distill_td_1.yaml\n",
      "hourglass_4__td_0__double.yaml\n",
      "hourglass_4__td_1.yaml\n",
      "hourglass_4__td_1__distill_td_0.yaml\n",
      "hourglass_4__td_1__distill_td_0_25.yaml\n",
      "hourglass_4__td_1__distill_td_0_5.yaml\n",
      "hourglass_4__td_1__distill_td_0_9.yaml\n",
      "hourglass_4__td_1__distill_td_1.yaml\n",
      "hourglass_4__td_1__double.yaml\n",
      "hourglass_8__td_0.yaml\n",
      "hourglass_8__td_0_25.yaml\n",
      "hourglass_8__td_0_25__distill_td_0.yaml\n",
      "hourglass_8__td_0_25__distill_td_0_5.yaml\n",
      "hourglass_8__td_0_25__distill_td_1.yaml\n",
      "hourglass_8__td_0_25__distill_td_1_untied.yaml\n",
      "hourglass_8__td_0_25_untied.yaml\n",
      "hourglass_8__td_0_5.yaml\n",
      "hourglass_8__td_0_5__distill_td_0.yaml\n",
      "hourglass_8__td_0_5__distill_td_0_5.yaml\n",
      "hourglass_8__td_0_5__distill_td_1.yaml\n",
      "hourglass_8__td_0_5__distill_td_1_untied.yaml\n",
      "hourglass_8__td_0_5_untied.yaml\n",
      "hourglass_8__td_0_9.yaml\n",
      "hourglass_8__td_0_9__distill_td_0.yaml\n",
      "hourglass_8__td_0_9__distill_td_0_5.yaml\n",
      "hourglass_8__td_0_9__distill_td_1.yaml\n",
      "hourglass_8__td_0_9__distill_td_1_untied.yaml\n",
      "hourglass_8__td_0_9_untied.yaml\n",
      "hourglass_8__td_0__distill_td_0.yaml\n",
      "hourglass_8__td_0__distill_td_0_5.yaml\n",
      "hourglass_8__td_0__distill_td_1.yaml\n",
      "hourglass_8__td_0__distill_td_1_untied.yaml\n",
      "hourglass_8__td_0_untied.yaml\n",
      "hourglass_8__td_1.yaml\n",
      "hourglass_8__td_1__distill_td_0.yaml\n",
      "hourglass_8__td_1__distill_td_0_5.yaml\n",
      "hourglass_8__td_1__distill_td_1.yaml\n",
      "hourglass_8__td_1__distill_td_1_singlehead.yaml\n",
      "hourglass_8__td_1__distill_td_1_untied.yaml\n",
      "hourglass_8__td_1_untied.yaml\n"
     ]
    }
   ],
   "source": [
    "[print(ele) for ele in np.sort(os.listdir(root)) if ele.endswith(\".yaml\")];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg_path = os.path.join(root, \"hourglass_8__teacher.yaml\")\n",
    "# cfg_path = os.path.join(root, \"hourglass_8__td_1__no_shared__distill.yaml\")\n",
    "cfg_path = os.path.join(root, \"hourglass_8__td_1__distill_td_1_singlehead.yaml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-261-e95f61268cc2>:4: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  exp_config = edict(yaml.load(f))\n"
     ]
    }
   ],
   "source": [
    "args = parse_args(cfg_path)\n",
    "reset_config(config, args)\n",
    "config = update_config(config, args.cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/mpii/hourglass_x8__TD_1.0__single_head\n"
     ]
    }
   ],
   "source": [
    "output_dir = create_experiment_directory(\n",
    "    config,\n",
    "    args.cfg,\n",
    "    distillation=False,\n",
    "    make_dir=False,\n",
    ")\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharing weights!\n"
     ]
    }
   ],
   "source": [
    "model = models.pose_stacked_hg.get_pose_net(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_params: 660,496\n"
     ]
    }
   ],
   "source": [
    "n_params = 0\n",
    "for key, param in model.named_parameters():\n",
    "  if param.requires_grad:\n",
    "    n_params += param.numel() \n",
    "print(f\"n_params: {n_params:,}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x_data, log_flops=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.518339072,\n",
       " 1.036678144,\n",
       " 1.555017216,\n",
       " 2.073356288,\n",
       " 2.59169536,\n",
       " 3.110034432,\n",
       " 3.628373504,\n",
       " 4.146712576]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.total_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.total_flops, \"student_gflops.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  8.18285158,  24.54855475,  49.0971095 ,  81.82851584,\n",
       "       122.74277376, 171.83988326, 229.11984435, 294.58265702])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cumsum(model.total_flops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.182851584,\n",
       " 16.365703168,\n",
       " 24.548554752,\n",
       " 32.731406336,\n",
       " 40.91425792,\n",
       " 49.097109504,\n",
       " 57.279961088,\n",
       " 65.462812672]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.total_flops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model GPU memory consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_bytes(size):\n",
    "    # 2**10 = 1024\n",
    "    power = 2**10\n",
    "    n = 0\n",
    "    power_labels = {0 : '', 1: 'kilo', 2: 'mega', 3: 'giga', 4: 'tera'}\n",
    "    while size > power:\n",
    "        size /= power\n",
    "        n += 1\n",
    "    return size, power_labels[n]+'bytes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(219.00628280639648, 'megabytes')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mem_params = sum([param.nelement()*param.element_size() for param in model.parameters()])\n",
    "mem_bufs = sum([buf.nelement()*buf.element_size() for buf in model.buffers()])\n",
    "mem = mem_params + mem_bufs # in bytes\n",
    "format_bytes(mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14857660"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.total_flops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.flops_benchmarker"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
